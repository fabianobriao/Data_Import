{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dataimport.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "12XY55FG4kMy7GLP9SzIdS5w5KO4D8NDX",
      "authorship_tag": "ABX9TyMGm1+EdWuraeSvrpxCQMAw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fabianobriao/Data_Import/blob/main/dataimport.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZEGnKBI_iv8"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnIjbR7aB9sx"
      },
      "source": [
        "## Este repositório é exclusivo para mostrar importações de dados através de diversos tipos de arquivos existentes em várias bases de dados. Ressalto que neste repositório é dedicado para a prepaparação e limpeza dos dos dados, esse tipo de ação é apresentada no repositório Data_Scrubbing.\n",
        "\n",
        "## Os scripts foram construídos na ide PyCharm, por isso algumas sintaxes possam parecer diferentes das usuais para usuários mais habituados ao Google Colaboratory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzQrq7uV0v60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c81fa72-208b-449d-d479-d6d0de85b497"
      },
      "source": [
        "!pip install geopandas"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting geopandas\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/bf/e9cefb69d39155d122b6ddca53893b61535fa6ffdad70bf5ef708977f53f/geopandas-0.9.0-py2.py3-none-any.whl (994kB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 5.1MB/s \n",
            "\u001b[?25hCollecting pyproj>=2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/1d/1c54c672c2faf08d28fe78e15d664c048f786225bef95ad87b6c435cf69e/pyproj-3.1.0-cp37-cp37m-manylinux2010_x86_64.whl (6.6MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6MB 20.4MB/s \n",
            "\u001b[?25hCollecting fiona>=1.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/fc/9807326c37a6bfb2393ae3e1cca147aa74844562c4d5daa782d6e97ad2bc/Fiona-1.8.20-cp37-cp37m-manylinux1_x86_64.whl (15.4MB)\n",
            "\u001b[K     |████████████████████████████████| 15.4MB 218kB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from geopandas) (1.1.5)\n",
            "Requirement already satisfied: shapely>=1.6 in /usr/local/lib/python3.7/dist-packages (from geopandas) (1.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from pyproj>=2.2.0->geopandas) (2020.12.5)\n",
            "Requirement already satisfied: six>=1.7 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (1.15.0)\n",
            "Collecting munch\n",
            "  Downloading https://files.pythonhosted.org/packages/cc/ab/85d8da5c9a45e072301beb37ad7f833cd344e04c817d97e0cc75681d248f/munch-2.5.0-py2.py3-none-any.whl\n",
            "Collecting click-plugins>=1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e9/da/824b92d9942f4e472702488857914bdd50f73021efea15b4cad9aca8ecef/click_plugins-1.1.1-py2.py3-none-any.whl\n",
            "Collecting cligj>=0.5\n",
            "  Downloading https://files.pythonhosted.org/packages/73/86/43fa9f15c5b9fb6e82620428827cd3c284aa933431405d1bcf5231ae3d3e/cligj-0.7.2-py3-none-any.whl\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (57.0.0)\n",
            "Requirement already satisfied: attrs>=17 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (21.2.0)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (7.1.2)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->geopandas) (1.19.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->geopandas) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->geopandas) (2.8.1)\n",
            "Installing collected packages: pyproj, munch, click-plugins, cligj, fiona, geopandas\n",
            "Successfully installed click-plugins-1.1.1 cligj-0.7.2 fiona-1.8.20 geopandas-0.9.0 munch-2.5.0 pyproj-3.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWu3iBo-sdpv"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xlrd\n",
        "import json\n",
        "import geopandas as gpd"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8v896M6vn9q"
      },
      "source": [
        "## CSV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQGRdE4wuc4O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3637d4fa-0dfd-4003-f3e8-75a5f19984c2"
      },
      "source": [
        "## importe de arquivos csv (1º caso)\n",
        "file = \"/content/drive/MyDrive/Colab_Notebooks/Data_Import/Resp2.csv\"\n",
        "df1 = pd.read_csv(file)\n",
        "print(df1.head(3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   experience  respiration\n",
            "0           0         3.94\n",
            "1           0         4.26\n",
            "2           0         4.16\n",
            "3           0         3.76\n",
            "4           0         4.07\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_d9af0_-v1Rw",
        "outputId": "90e9bcf1-c8f5-495e-a201-8b4bbe10f74b"
      },
      "source": [
        "## importe de arquivos csv (2º caso, arquivo separado por ;)\n",
        "file = \"/content/drive/MyDrive/Colab_Notebooks/Data_Import/Churn.csv\"\n",
        "df2 = pd.read_csv(file, sep = \";\")\n",
        "print(df2.head(3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   X0   X1  X2        X3  X4  X4.1       X6  X7  X8  X9         X10  X11\n",
            "0   1  619  RS  Feminino  42     2        0   1   1   1  10134888.0    1\n",
            "1   2  608  SC  Feminino  41     1  8380786   1   0   1  11254258.0    0\n",
            "2   3  502  RS  Feminino  42     8  1596608   3   1   0  11393157.0    1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_kDLMCjNV32"
      },
      "source": [
        "## XLS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpCfDrdOvWVW",
        "outputId": "0a97f08d-34fa-481b-e29d-3effd2cb4b2d"
      },
      "source": [
        "## importe de arquivos xls\n",
        "file = \"/content/drive/MyDrive/Colab_Notebooks/Data_Import/boston1.xls\"\n",
        "df2 = pd.ExcelFile(file) #tem que instalar o xlrd\n",
        "print(df2.sheet_names)\n",
        "df2 = df2.parse('Sheet2')\n",
        "print(df2.head(3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Sheet1', 'Sheet2']\n",
            "     MV  INDUS   NOX     RM  TAX    PT  LSTAT\n",
            "0  24.0   2.31  53.8  6.575  296  15.3   4.98\n",
            "1  21.6   7.07  46.9  6.421  242  17.8   9.14\n",
            "2  34.7   7.07  46.9  7.185  242  17.8   4.03\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bl9YR3BmNRGR"
      },
      "source": [
        "## XLSX"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLwfrEiavVjg",
        "outputId": "67872bf6-84b8-44ba-bc29-1ad4bcc539ad"
      },
      "source": [
        "## importe de arquivos xlsx # tem que instalar o xlrd\n",
        "#import xlrd\n",
        "file = \"/content/drive/MyDrive/Colab_Notebooks/Data_Import/boston11.xlsx\"\n",
        "df2 = pd.ExcelFile(file) \n",
        "print(df2.sheet_names)\n",
        "df2 = df2.parse('Planilha3')\n",
        "print(df2.head(10))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Sheet1', 'Sheet2', 'Planilha3']\n",
            "     MV  INDUS\n",
            "0  24.0   2.31\n",
            "1  21.6   7.07\n",
            "2  34.7   7.07\n",
            "3  33.4   2.18\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eE-AlkK21Zv6",
        "outputId": "93bca567-9941-42c8-a36c-4e2d3a2d002f"
      },
      "source": [
        "## importe de planilha da internet (no pycharm é necessário instalar lxml)\n",
        "site = \"https://pt.wikipedia.org/wiki/Unidades_federativas_do_Brasil\" # tem que importar html5lib\n",
        "br = pd.read_html(site)\n",
        "print(type(br))\n",
        "print(br[0].head(5)) # havendo mais de uma tabela puxamos pelo índice\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "              0                                       1           2\n",
            "0    Capítulo I  Da Organização Político-Administrativa  art. 18-19\n",
            "1   Capítulo II                                Da União  art. 20-24\n",
            "2  Capítulo III                   Dos Estados Federados  art. 25-28\n",
            "3   Capítulo IV                          Dos Municípios  art. 29-31\n",
            "4    Capítulo V   Do Distrito Federal e dos Territórios  art. 32-33\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7wpTDW7NJHV"
      },
      "source": [
        "## JSON"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3ARvsi82dEB",
        "outputId": "95404c72-b35a-48a8-f121-c7a2cc06956e"
      },
      "source": [
        "# importe de arquivos json\n",
        "# import json\n",
        "file = \"/content/drive/MyDrive/Colab_Notebooks/Data_Import/skorea.json\"\n",
        "with open(file) as j:\n",
        "    Json = json.load(j)\n",
        "#print(Json)\n",
        "df3 = pd.DataFrame(Json)\n",
        "print(df3.head(4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[{'Description': '', 'Image': '/wiki/File:MuryeongsTomb.jpg', 'Criteria': 'Cultural: (ii)(iii)', 'Site': 'Baekje Historic Areas', 'Area ha (acre)': '135 (330)', 'Location': 'South Chungcheong, North Jeolla', 'Year': '2015'}, {'Description': '', 'Image': '/wiki/File:Korea-Gwangju-Gochang_Dolmens_5350-06.JPG', 'Criteria': 'Cultural: (iii)', 'Site': 'Gochang, Hwasun and Ganghwa Dolmen Sites', 'Area ha (acre)': '', 'Location': 'Incheon, North Jeolla, South Jeolla', 'Year': '2000'}, {'Description': '', 'Image': '/wiki/File:Juhamnu,_Changdeokgung_-_Seoul,_Korea.JPG', 'Criteria': 'Cultural: (ii)(iii)(iv)', 'Site': 'Changdeokgung Palace Complex', 'Area ha (acre)': '', 'Location': 'Seoul', 'Year': '1997'}, {'Description': '', 'Image': '/wiki/File:Korea-Gyeongju-Bunhwangsa-Lanterns-03.jpg', 'Criteria': 'Cultural: (ii)(iii)', 'Site': 'Gyeongju Historic Areas', 'Area ha (acre)': '2,880 (7,100)', 'Location': 'North Gyeongsang', 'Year': '2000'}, {'Description': '', 'Image': '/wiki/File:Haeinsa_Temple_(6222053899).jpg', 'Criteria': 'Cultural: (iv)(vi)', 'Site': 'Haeinsa Temple Janggyeong Panjeon, the Depositories for the Tripitaka Koreana Woodblocks', 'Area ha (acre)': '', 'Location': 'South Gyeongsang', 'Year': '1995'}, {'Description': '', 'Image': '/wiki/File:Hahoe_8784.jpg', 'Criteria': 'Cultural: (iii)(iv)', 'Site': 'Historic Villages of Korea: Hahoe and Yangdong', 'Area ha (acre)': '600 (1,500)', 'Location': 'North Gyeongsang', 'Year': '2010'}, {'Description': '', 'Image': '/wiki/File:Hwaseong2.jpg', 'Criteria': 'Cultural: (ii)(iii)', 'Site': 'Hwaseong Fortress', 'Area ha (acre)': '', 'Location': 'Gyeonggi', 'Year': '1997'}, {'Description': '', 'Image': '/wiki/File:KOCIS_Halla_Mountain_in_Jeju-do_(6387785543).jpg', 'Criteria': 'Natural: (vii)(viii)', 'Site': 'Jeju Volcanic Island and Lava Tubes', 'Area ha (acre)': '9,475 (23,410)', 'Location': 'Jeju', 'Year': '2007'}, {'Description': '', 'Image': '/wiki/File:Chongmyo_repository_(1509268349).jpg', 'Criteria': 'Cultural: (iv)', 'Site': 'Jongmyo Shrine', 'Area ha (acre)': '19 (47)', 'Location': 'Seoul', 'Year': '1995'}, {'Description': '', 'Image': '/wiki/File:Khitai5.jpg', 'Criteria': 'Cultural: (ii)(iv)', 'Site': 'Namhansanseong', 'Area ha (acre)': '409 (1,010)', 'Location': 'Gyeonggi', 'Year': '2014'}, {'Description': '', 'Image': '/wiki/File:Sejong_tomb_1.jpg', 'Criteria': 'Cultural: (iii)(iv)(vi)', 'Site': 'Royal Tombs of the Joseon Dynasty', 'Area ha (acre)': '1,891 (4,670)', 'Location': 'Gyeonggi, Seoul', 'Year': '2009'}, {'Description': '', 'Image': '/wiki/File:Bulguk_Tempel.jpg', 'Criteria': 'Cultural: (i)(iv)', 'Site': 'Seokguram Grotto and Bulguksa Temple', 'Area ha (acre)': '', 'Location': 'North Gyeongsang', 'Year': '1995'}]\n",
            "  Description  ...  Year\n",
            "0              ...  2015\n",
            "1              ...  2000\n",
            "2              ...  1997\n",
            "3              ...  2000\n",
            "\n",
            "[4 rows x 7 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qi8KxEDv59_3",
        "outputId": "e4909276-ee3a-4219-8ada-ec313cc7a013"
      },
      "source": [
        "# importe de arquivos json - amostra de dados extraída de dehttps://servicodados.ibge.gov.br/api/v1/localidades/distritos\n",
        "# import json\n",
        "file = \"/content/drive/MyDrive/Colab_Notebooks/Data_Import/municipio.json\"\n",
        "with open(file) as j:\n",
        "    Json = json.load(j)\n",
        "#print(Json)\n",
        "df4 = pd.DataFrame(Json)\n",
        "print(df4.head(4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "          id  ...                                          municipio\n",
            "0  520005005  ...  {'id': 5200050, 'nome': 'Abadia de Goiás', 'mi...\n",
            "1  310010405  ...  {'id': 3100104, 'nome': 'Abadia dos Dourados',...\n",
            "2  520010005  ...  {'id': 5200100, 'nome': 'Abadiânia', 'microrre...\n",
            "3  520010010  ...  {'id': 5200100, 'nome': 'Abadiânia', 'microrre...\n",
            "\n",
            "[4 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixs1QVDINDUq"
      },
      "source": [
        "## GPD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkBHF1q6CMzK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "70152bf6-0f90-42b9-a937-99790cab20ac"
      },
      "source": [
        "# Importe de arquivos shp - precisamos instalar o geopandas\n",
        "#import geopandas as gpd\n",
        "file = \"/content/drive/MyDrive/Colab_Notebooks/Data_Import/AL_Municipios_2020/AL_Municipios_2020.shp\"\n",
        "gpd.read_file(file.head(3))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-6683f34d4c56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#import geopandas as gpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/Colab_Notebooks/Data_Import/AL_Municipios_2020/AL_Municipios_2020.shp\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mgpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'head'"
          ]
        }
      ]
    }
  ]
}